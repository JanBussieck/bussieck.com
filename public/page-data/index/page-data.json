{"componentChunkName":"component---src-templates-index-js","path":"/","result":{"data":{"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5e9d7c13fb708a9e1ad89877","title":"useEffect under the Hood","slug":"useeffect-under-the-hood","featured":false,"feature_image":"https://images.unsplash.com/photo-1560024253-570f054dea63?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ","excerpt":"To deepen our understanding of the inner workings of useEffect and how it relates to the lifecycle of a component we take a look at React's source code.","custom_excerpt":"To deepen our understanding of the inner workings of useEffect and how it relates to the lifecycle of a component we take a look at React's source code.","visibility":"public","created_at_pretty":"20 April, 2020","published_at_pretty":"20 April, 2020","updated_at_pretty":"23 April, 2020","created_at":"2020-04-20T10:40:19.000+00:00","published_at":"2020-04-20T11:16:19.000+00:00","updated_at":"2020-04-23T12:37:07.000+00:00","meta_title":null,"meta_description":null,"og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Jan Bussieck","slug":"jan","bio":null,"profile_image":"//www.gravatar.com/avatar/e056f0b055ea37bd94fdc1664fca6e3d?s=250&d=mm&r=x","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Jan Bussieck","slug":"jan","bio":null,"profile_image":"//www.gravatar.com/avatar/e056f0b055ea37bd94fdc1664fca6e3d?s=250&d=mm&r=x","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"hooks","slug":"hooks","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"hooks","slug":"hooks","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"react","slug":"react","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Tech","slug":"tech","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"The best way I have found to really have an accurate mental model of the\nprogramming abstractions I use whether compilers, promises or frameworks like\nreact, it is to crack open the blackbox and understand the essential\nimplementation details.\nWhile there are a number of excellent posts on how hooks work under the hood\n[https://www.netlify.com/blog/2019/03/11/deep-dive-how-do-react-hooks-really-work/]\n, the inner workings of useEffect and how it relates to the lifecycle of a\ncomponent continue to be a source of puzzlement for many.\nAs I’ll attempt to show when you peak behind the curtain the useEffect hook’s\nimplementation is quite straightforward and fits elegantly into React’s\nreconciliation algorithm.\nBy the end I hope we’ll be able to confidently answer questions such as:\n\n * Why do we have to call useEffect hooks in the same order?\n * How are hooks represented by a fiber?\n * When and how exactly are values in the dependency array compared?\n * When and how are effects cleaned up?\n * Why can’t we take advantage of React fibers in my useEffect callbacks?\n\nFirst, let’s briefly recap how React fibers and the reconciliation algorithm\nwork; during reconciliation React builds up a work-in-progress fiber tree and\ncomputes a set of changes by walking the component tree and recursively calling \nrender. Each React element is thus turned into a fiber node ofcorresponding type\n[https://github.com/facebook/react/blob/769b1f270e1251d9dbdce0fcbd9e92e502d059b8/packages/shared/ReactWorkTags.js] \nthat keeps record of the work to be done. Think of a fiber as representing a\nunit of work that can be independently scheduled, paused and aborted.\nWhen an update is called, React will add the update to a component update queue,\nfor instance, when setState is called on render, React calls the updater\nfunction which was passed into setState. After the updater is finished the fiber\ngets a tag that a change needs to be made in the DOM.\nThe list of changes are then propagated up to the parent fiber and merged into\nits list of changes. This list of changes is also called effect list. When React\nreaches the root node the work in progress tree is marked as a pending commit.\n\nThose changes, however, are not immediately committed to a rendering target such\nas the DOM.  That happens in the commit phase, this phase is atomic and cannot\nbe interrupted, otherwise there might be UI inconsistencies.\nDuring the commit phase React iterates over the effect list and makes its\nchanges to the rendering target (e.g. DOM).\n\nLet’s look at some code:\nuseEffect is defined in ReactHooks.js and its type signature clues us in to how\nit works; it accepts as first argument a function creating the effect, which\noptionally returns a function (cleaning up the effect) and as second argument an\noptional array of inputs (the dependency array) of variable type.\nWe see that the functions first resolves a dispatcher and then delegates to it.\n\n//react/blob/master/packages/react/src/ReactHooks.js#L104\nexport function useEffect(\n  create: () => (() => void) | void,\n  inputs: Array<mixed> | void | null,\n) {\n  const dispatcher = resolveDispatcher();\n  return dispatcher.useEffect(create, inputs);\n}\n\n\nThe hook dispatchers are resolved depending on the current context, if it's the\ninitial render and the component just mounted HooksDispatcherOnMount and\notherwise HooksDispatcherOnUpdate is returned, correspondingly the dispatcher\nreturns either mountEffect or updateEffect.\n\n//react/blob/master/packages/react-reconciler/src/ReactFiberHooks.old.js#L570\nconst HooksDispatcherOnMount: Dispatcher = {\n\t...\n  useEffect: mountEffect,\n  ...\n};\n\nconst HooksDispatcherOnUpdate: Dispatcher = {\n  ...\n  useEffect: updateEffect,\n  ...\n}\n\n\nWithout looking at the implementation, from our experience working with \nuseEffect we know that these cases differ in at least one respect; the create\nfunction of useEffect is always invoked on mount, regardless of its second\nargument.\n\nLet us first look at the more common update case; updateEffect delegates to \nupdateEffectImpl to pass in the current fiber and hook effect tags. I don’t want\nto go too much into effect tags here, suffice it to mention that each fiber’s\neffects are encoded in an effectTag, they define  thework\n[https://github.com/facebook/react/blob/b87aabdfe1b7461e7331abb3601d9e6bb27544bc/packages/shared/ReactSideEffectTags.js] \nthat needs to be done for instances after updates have been processed, similarly\nthere are hook effect tags carrying information about the hook effect's context,\ne.g. whether the component is unmounting or whether the effect should be invoked\nat all (the NoHookEffect tag).\nupdateEffectImpl first calls updateWorkInProgressHook to get a new hook\ninstance, which is basically just a clone of the current hook or if we are in a\nwork-in-progress tree the current work-in-progress hook:\n\nconst newHook: Hook = {\n  memoizedState: currentHook.memoizedState,\n\n  baseState: currentHook.baseState,\n  queue: currentHook.queue,\n  baseUpdate: currentHook.baseUpdate,\n\n  next: null,\n};\n\n\nWhen a hook is called in our component it builds up a queue where hooks are\nrepresented as linked list in their call order with each hook’s next field\npointing to the next hook. Since these are copied over from each render, we see\nwhy we cannot call hooks conditionally or change their call order from render to\nrender.\nThe baseState and baseUpdate fields are relevant to useState and useDispatch \nhooks,useEffect most importantly uses memoizedState to hold a reference to the\nprevious effect. Let’s look at why.\n\n//react/packages/react-reconciler/src/ReactFiberHooks.old.js#L1218\nfunction updateEffectImpl(fiberEffectTag, hookEffectTag, create, deps): void {\n  const hook = updateWorkInProgressHook();\n  const nextDeps = deps === undefined ? null : deps;\n  let destroy = undefined;\n\n  if (currentHook !== null) {\n    const prevEffect = currentHook.memoizedState;\n    destroy = prevEffect.destroy;\n    if (nextDeps !== null) {\n      const prevDeps = prevEffect.deps;\n      if (areHookInputsEqual(nextDeps, prevDeps)) {\n        pushEffect(NoHookEffect, create, destroy, nextDeps);\n        return;\n      }\n    }\n  }\n\n  sideEffectTag |= fiberEffectTag;\n  hook.memoizedState = pushEffect(hookEffectTag, create, destroy, nextDeps);\n}\n\n\nThe most interesting thing happening here is that if there is a currentHook we\nfetch the previous effect from the hook’s memoizedState field to get the\nprevious dependencies and compare them to the next dependencies. If they are\nequal, we push an effect onto the queue with the NoHookEffect tag and return,\nwhich means that the effect will still be run during commit, but it won’t be\nexecuted (its create function won't be invoked). Finally, if the dependencies\nare not equal, we push the effect onto the queue with an effect tag that ensures\nthe effect will fire.\nAs a side note areHookInputsEqual delegates to Object.is instead of a plain\nobject reference comparison to catch javascript quirks such as NaN === NaN //\nfalse.\n\nWe skip over the source ofmountEffectImpl here, since it only differs from \nupdateEffectImpl in that it does not check the dependency array and simply\npushes the hook on the effect queue to be executed.\n\nThat is basically all that happens during reconciliation; values from previous\nuseEffect hooks are cloned, the new dependencies compared to previous ones which\nwere saved on the memoizedState field to determine whether the effect should\nfire or not and that information is pushed on the effect queue.\n\nThe next time we see our effect is after React has finished reconciliation,\nevery render has been called and the list of updates to be committed to the\nrendering target aggregated. We are in the commit phase now and commitWork calls \ncommitHookEffectList:\n\nfunction commitWork(current: Fiber | null, finishedWork: Fiber): void {\n\t...\n  commitHookEffectList(UnmountMutation, MountMutation, finishedWork);\n\t...\n}\n\n\n commitHookEffectList in turn iterates over the effect list, checks the tag to\ndetermine in which phase the effect has been added to the list and fires create \nor destroy respectively.\nWe see that in the case of an unmountTag the destroy clean up function is\ncalled. In case, we are in an update phase, create is called firing the effect\nand the destroy function returned from `createz is simply saved on the effect\nfor future reference in the unmount phase. If the effect has been tagged with \nNoHookEffect it is simply skipped.\n\n// react/ReactFiberCommitWork.old.js at master · facebook/react\nfunction commitHookEffectList(\n  unmountTag: number,\n  mountTag: number,\n  finishedWork: Fiber,\n) {\n  const updateQueue: FunctionComponentUpdateQueue | null = (finishedWork.updateQueue: any);\n  let lastEffect = updateQueue !== null ? updateQueue.lastEffect : null;\n  if (lastEffect !== null) {\n    const firstEffect = lastEffect.next;\n    let effect = firstEffect;\n    do {\n      if ((effect.tag & unmountTag) !== NoHookEffect) {\n        // Unmount\n        const destroy = effect.destroy;\n        effect.destroy = undefined;\n        if (destroy !== undefined) {\n          destroy();\n        }\n      }\n      if ((effect.tag & mountTag) !== NoHookEffect) {\n        // Mount\n        const create = effect.create;\n        effect.destroy = create();\n\n        if (__DEV__) {...}\n      }\n      effect = effect.next;\n    } while (effect !== firstEffect);\n  }\n}\n\n\nNow we also see why the code we run in useEffect cannot take advantage of fibers\nwhich are able to pause in order to let other higher priority work finish before\nrendering is resumed. This is because the effect is executed inside of \ncommitWork which makes atomic changes to the rendering target to avoid UI\ninconsistencies. This is important to bear in mind lest one is tempted to\nperform computationally intensive, synchronous work inside a useEffect hook.\n\nI hope this basic understanding of how useEffect works under the hood helps you\nbecome more confident working with useEffect and avoid common pitfalls. It may\nalso have encouraged you to pull away the curtain once in a while and take a\nlook at the React source to deepen your understanding. The most difficult to\nunderstand parts of the code are often related to performance and other\nhouse-keeping, but you shouldn't let that shroud your understanding of the\ncentral pieces that are concerned with React’s core functionality.\nHappy source reading!","html":"<p>The best way I have found to really have an accurate mental model of the programming abstractions I use whether compilers, promises or frameworks like react, it is to crack open the blackbox and understand the essential implementation details.<br>While there are a number of excellent posts on <a href=\"https://www.netlify.com/blog/2019/03/11/deep-dive-how-do-react-hooks-really-work/\">how hooks work under the hood</a>, the inner workings of useEffect and how it relates to the lifecycle of a component continue to be a source of puzzlement for many.<br>As I’ll attempt to show when you peak behind the curtain the <code>useEffect</code> hook’s implementation is quite straightforward and fits elegantly into React’s reconciliation algorithm.<br>By the end I hope we’ll be able to confidently answer questions such as:</p><ul><li>Why do we have to call <code>useEffect</code> hooks in the same order?</li><li>How are hooks represented by a fiber?</li><li>When and how exactly are values in the dependency array compared?</li><li>When and how are effects cleaned up?</li><li>Why can’t we take advantage of React fibers in my useEffect callbacks?</li></ul><p>First, let’s briefly recap how React fibers and the reconciliation algorithm work; during reconciliation React builds up a work-in-progress fiber tree and computes a set of changes by walking the component tree and recursively calling <code>render</code>. Each React element is thus turned into a fiber node of  <a href=\"https://github.com/facebook/react/blob/769b1f270e1251d9dbdce0fcbd9e92e502d059b8/packages/shared/ReactWorkTags.js\">corresponding type</a>  that keeps record of the work to be done. Think of a fiber as representing a unit of work that can be independently scheduled, paused and aborted.<br>When an update is called, React will add the update to a component update queue, for instance, when setState is called on render, React calls the updater function which was passed into setState. After the updater is finished the fiber gets a <em>tag</em> that a change needs to be made in the DOM.<br>The list of changes are then propagated up to the parent fiber and merged into its list of changes. This list of changes is also called <em>effect list</em>. When React reaches the root node the work in progress tree is marked as a pending commit.</p><p>Those changes, however, are not immediately committed to a rendering target such as the DOM.  That happens in the <em>commit</em> phase, this phase is atomic and cannot be interrupted, otherwise there might be UI inconsistencies.<br>During the commit phase React iterates over the effect list and makes its changes to the rendering target (e.g. DOM).</p><p>Let’s look at some code:<br><code>useEffect</code> is defined in <code>ReactHooks.js</code> and its type signature clues us in to how it works; it accepts as first argument a function creating the effect, which optionally returns a function (cleaning up the effect) and as second argument an optional array of inputs (the dependency array) of variable type.<br>We see that the functions first resolves a dispatcher and then delegates to it.</p><pre><code class=\"language-javascript\">//react/blob/master/packages/react/src/ReactHooks.js#L104\nexport function useEffect(\n  create: () =&gt; (() =&gt; void) | void,\n  inputs: Array&lt;mixed&gt; | void | null,\n) {\n  const dispatcher = resolveDispatcher();\n  return dispatcher.useEffect(create, inputs);\n}\n</code></pre><p>The hook dispatchers are resolved depending on the current context, if it's the initial render and the component just mounted <code>HooksDispatcherOnMount</code> and otherwise <code>HooksDispatcherOnUpdate</code> is returned, correspondingly the dispatcher returns either <code>mountEffect</code> or <code>updateEffect</code>.</p><pre><code class=\"language-javascript\">//react/blob/master/packages/react-reconciler/src/ReactFiberHooks.old.js#L570\nconst HooksDispatcherOnMount: Dispatcher = {\n\t...\n  useEffect: mountEffect,\n  ...\n};\n\nconst HooksDispatcherOnUpdate: Dispatcher = {\n  ...\n  useEffect: updateEffect,\n  ...\n}\n</code></pre><p>Without looking at the implementation, from our experience working with <code>useEffect</code> we know that these cases differ in at least one respect; the create function of <code>useEffect</code> is always invoked on mount, regardless of its second argument.</p><p>Let us first look at the more common update case; <code>updateEffect</code> delegates to <code>updateEffectImpl</code>  to pass in the current fiber and hook effect tags. I don’t want to go too much into effect tags here, suffice it to mention that each fiber’s effects are encoded in an <code>effectTag</code>, they define  the  <a href=\"https://github.com/facebook/react/blob/b87aabdfe1b7461e7331abb3601d9e6bb27544bc/packages/shared/ReactSideEffectTags.js\">work</a>  that needs to be done for instances after updates have been processed, similarly there are hook effect tags carrying information about the hook effect's context, e.g. whether the component is unmounting or whether the effect should be invoked at all (the <code>NoHookEffect</code> tag).<br><code>updateEffectImpl</code> first calls <code>updateWorkInProgressHook</code> to get a new hook instance, which is basically just a clone of the current hook or if we are in a work-in-progress tree the current work-in-progress hook:</p><pre><code class=\"language-javascript\">const newHook: Hook = {\n  memoizedState: currentHook.memoizedState,\n\n  baseState: currentHook.baseState,\n  queue: currentHook.queue,\n  baseUpdate: currentHook.baseUpdate,\n\n  next: null,\n};\n</code></pre><p>When a hook is called in our component it builds up a queue where hooks are represented as linked list in their call order with each hook’s <code>next</code> field pointing to the next hook. Since these are copied over from each render, we see why we cannot call hooks conditionally or change their call order from render to render.<br>The <code>baseState</code> and <code>baseUpdate</code> fields are relevant to <code>useState</code> and <code>useDispatch</code> hooks,  <code>useEffect</code> most importantly uses <code>memoizedState</code> to hold a reference to the previous effect. Let’s look at why.</p><pre><code class=\"language-javascript\">//react/packages/react-reconciler/src/ReactFiberHooks.old.js#L1218\nfunction updateEffectImpl(fiberEffectTag, hookEffectTag, create, deps): void {\n  const hook = updateWorkInProgressHook();\n  const nextDeps = deps === undefined ? null : deps;\n  let destroy = undefined;\n\n  if (currentHook !== null) {\n    const prevEffect = currentHook.memoizedState;\n    destroy = prevEffect.destroy;\n    if (nextDeps !== null) {\n      const prevDeps = prevEffect.deps;\n      if (areHookInputsEqual(nextDeps, prevDeps)) {\n        pushEffect(NoHookEffect, create, destroy, nextDeps);\n        return;\n      }\n    }\n  }\n\n  sideEffectTag |= fiberEffectTag;\n  hook.memoizedState = pushEffect(hookEffectTag, create, destroy, nextDeps);\n}\n</code></pre><p>The most interesting thing happening here is that if there is a <code>currentHook</code> we fetch the previous effect from the hook’s <code>memoizedState</code> field to get the previous dependencies and compare them to the next dependencies. If they are equal, we push an effect onto the queue with the <code>NoHookEffect</code> tag and return, which means that the effect will still be run during commit, but it won’t be executed (its <code>create</code> function won't be invoked). Finally, if the dependencies are not equal, we push the effect onto the queue with an effect tag that ensures the effect will fire.<br>As a side note <code>areHookInputsEqual</code> delegates to <code>Object.is</code> instead of a plain object reference comparison to catch javascript quirks such as <code>NaN === NaN // false</code>.</p><p>We skip over the source of<code>mountEffectImpl</code> here, since it only differs from <code>updateEffectImpl</code> in that it does not check the dependency array and simply pushes the hook on the effect queue to be executed.</p><p>That is basically all that happens during reconciliation; values from previous useEffect hooks are cloned, the new dependencies compared to previous ones which were saved on the <code>memoizedState</code> field to determine whether the effect should fire or not and that information is pushed on the effect queue.</p><p>The next time we see our effect is after React has finished reconciliation, every render has been called and the list of updates to be committed to the rendering target aggregated. We are in the commit phase now and <code>commitWork</code> calls <code>commitHookEffectList</code>:</p><pre><code class=\"language-javascript\">function commitWork(current: Fiber | null, finishedWork: Fiber): void {\n\t...\n  commitHookEffectList(UnmountMutation, MountMutation, finishedWork);\n\t...\n}\n</code></pre><p> <code>commitHookEffectList</code> in turn iterates over the effect list, checks the tag to determine in which phase the effect has been added to the list and fires <code>create</code> or <code>destroy</code> respectively.<br>We see that in the case of an <code>unmountTag</code>  the <code>destroy</code> clean up function is called. In case, we are in an update phase, <code>create</code> is called firing the effect and the <code>destroy</code> function returned from `createz is simply saved on the effect for future reference in the unmount phase. If the effect has been tagged with <code>NoHookEffect</code> it is simply skipped.</p><pre><code class=\"language-javascript\">// react/ReactFiberCommitWork.old.js at master · facebook/react\nfunction commitHookEffectList(\n  unmountTag: number,\n  mountTag: number,\n  finishedWork: Fiber,\n) {\n  const updateQueue: FunctionComponentUpdateQueue | null = (finishedWork.updateQueue: any);\n  let lastEffect = updateQueue !== null ? updateQueue.lastEffect : null;\n  if (lastEffect !== null) {\n    const firstEffect = lastEffect.next;\n    let effect = firstEffect;\n    do {\n      if ((effect.tag &amp; unmountTag) !== NoHookEffect) {\n        // Unmount\n        const destroy = effect.destroy;\n        effect.destroy = undefined;\n        if (destroy !== undefined) {\n          destroy();\n        }\n      }\n      if ((effect.tag &amp; mountTag) !== NoHookEffect) {\n        // Mount\n        const create = effect.create;\n        effect.destroy = create();\n\n        if (__DEV__) {...}\n      }\n      effect = effect.next;\n    } while (effect !== firstEffect);\n  }\n}\n</code></pre><p>Now we also see why the code we run in <code>useEffect</code> cannot take advantage of fibers which are able to pause in order to let other higher priority work finish before rendering is resumed. This is because the effect is executed inside of <code>commitWork</code> which makes atomic changes to the rendering target to avoid UI inconsistencies. This is important to bear in mind lest one is tempted to perform computationally intensive, synchronous work inside a <code>useEffect</code> hook.</p><p>I hope this basic understanding of how <code>useEffect</code> works under the hood helps you become more confident working with <code>useEffect</code> and avoid common pitfalls. It may also have encouraged you to pull away the curtain once in a while and take a look at the React source to deepen your understanding. The most difficult to understand parts of the code are often related to performance and other house-keeping, but you shouldn't let that shroud your understanding of the central pieces that are concerned with React’s core functionality.<br>Happy source reading!</p>","url":"http://localhost:2368/useeffect-under-the-hood/","canonical_url":null,"uuid":"d60ae843-3af2-413f-95a5-18f27348a961","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5e9d7c13fb708a9e1ad89877","reading_time":6}},{"node":{"id":"Ghost__Post__5e858c4e0a554e19673f4bf4","title":"Decouple from Redux using Hooks","slug":"decouple-from-redux-using-hooks","featured":false,"feature_image":"https://images.unsplash.com/photo-1520359319979-f360d010d777?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ","excerpt":"We can use redux hooks to fully decouple our react components from redux or any state management solution. This leads to cleaner code that is easier to change.","custom_excerpt":"We can use redux hooks to fully decouple our react components from redux or any state management solution. This leads to cleaner code that is easier to change.","visibility":"public","created_at_pretty":"02 April, 2020","published_at_pretty":"03 April, 2020","updated_at_pretty":"29 April, 2020","created_at":"2020-04-02T06:55:10.000+00:00","published_at":"2020-04-03T14:35:44.000+00:00","updated_at":"2020-04-29T18:06:17.000+00:00","meta_title":"Decouple from Redux Using Hooks","meta_description":"We can use redux hooks to fully decouple our react components from redux or any state management solution. This leads to cleaner code that is easier to change.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Jan Bussieck","slug":"jan","bio":null,"profile_image":"//www.gravatar.com/avatar/e056f0b055ea37bd94fdc1664fca6e3d?s=250&d=mm&r=x","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Jan Bussieck","slug":"jan","bio":null,"profile_image":"//www.gravatar.com/avatar/e056f0b055ea37bd94fdc1664fca6e3d?s=250&d=mm&r=x","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"react","slug":"react","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"react","slug":"react","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"redux","slug":"redux","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"hooks","slug":"hooks","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Received wisdom in the react community holds that you should subdivide your\ncomponents into 'smart' containers and 'dumb', presentational components.\n\nThe rationale is to separate concerns. Logic and behavior such as data fetching,\nany interaction with the outside world, dispatching actions and other side\neffects go into our smart container and what our UI should look like as a\nfunction of the resulting data into our dumb component.\n\nThis idea leads to a pervasive pattern of creating container components solely\nfor the purpose of connecting a part of the component tree to the redux store.\nSo we end up with two components; one in a containers folder fetching data from\nthe store and passing down actions and the actual component in the components \nfolder. \n\nTo me, this quickly felt cumbersome and rigid, if I simply wanted a component to\nhave access to a slice of the store, I found myself having to create an\nintermediary container and changing a number of imports in other files that use\nthe component.\n\nI also stopped putting every bit of state into the redux store and instead took\nadvantage of react's new and improved context api to co-locate state\n[https://kentcdodds.com/blog/colocation] that is confined to a specific,\nwell-delineated part of the component tree. This raised questions such as\nwhether consuming context should also only happen inside containers. \n\nBesides, what are we really achieving by this kind of separation? Concerns about\ndata access still has us change a number of files in the component tree and the\nhierarchy of our UI seems to dictate which components should be containers (by\ndefault the top level one).\n\nWhile well-intentioned, the benefit of decoupling UI from state and behavior\ndoes not seem to warrant the overhead and complexity introduced by organizing\nfiles this way.\n\nLuckily, we have a perfect tool to decouple data and behavior from our\npresentational components...\n\nHooks!\n\nAnd wouldn't you know react-redux lets us consume its API only using hooks.\n\nLet's look at a small (and admittedly contrived) example. Say, we want to\nimplement a toggle button and keep the toggle state in the redux store, maybe it\nneeds to be available globally, toggling an app wide setting.\n\nThis is what such a component could look like using redux classico:\n\nimport React from \"react\";\nimport {connect} from \"react-redux\";\nimport {toggleAction} from \"./store/toggleActions\";\n\nconst Toggle = ({on, toggle}) => {\n  return (\n    <button onClick={toggle}>{on ? 'on' : 'off'}</button>\n  );\n};\n\nconst mapStateToProps = state => ({\n  on: state.toggle.on\n});\n\nconst mapDispatchToProps = {toggle: toggleAction};\n\nexport default connect(mapStateToProps, mapDispatchToProps)(Toggle);\n\n\nYes, we probably want this to be a container components wrapping a\npresentational component (e.g. a button) simply passing on and toggle down via\nprops, but for the sake of simplicity we're keeping everything in one component.\n\nNow let's refactor this to use the new redux hooks api:\n\nimport React from \"react\";\nimport {useDispatch, useSelector} from \"react-redux\";\nimport {toggleAction} from \"./store/toggleActions\";\n\nconst Toggle = () => {\n  const on = useSelector(state => state.toggle.on);\n  const dispatch = useDispatch();\n  return (\n    <button onClick={() => dispatch(toggleAction())}>{on ? 'on' : 'off'}</button>\n  );\n}\n\n\nNot much of an improvement, we reduced some boilerplate, but there is still a\nlot of redux code sitting in our component. \n\nThe beauty of hooks is how composable they are, we can just create a custom \nuseToggle hook:\n\nimport React from \"react\";\nimport {useDispatch, useSelector} from \"react-redux\";\nimport {toggleAction} from \"./store/toggleActions\";\n\nconst useToggle = () => {\n  const on = useSelector(state => state.toggle.on);\n  const dispatch = useDispatch();\n  const toggle = () =>  dispatch(toggleAction());\n  return [on, toggle];\n};\n\nconst Toggle = () => {\n  const [on, toggle] = useToggle();\n  return (\n    <button onClick={toggle()}>{on ? 'on' : 'off'}</button>\n  );\n};\n\nNow our component knows nothing about redux, we did not need to create a Toggle \ncontainer or some abstract HOC wrapping our button, we simply use a hook to\nencapsulates the data layer.\n\nThis way our components are also closed to modification, should we decide to\nemploy a different state management solution. Moving redux state into react\ncontext simply involves rewriting the hook (at least for consumers of the\ncontext):\n\nimport ToggleContext from './ToggleContext';\nconst useToggle = () => {\n  const {on, toggle} = useContext(ToggleContext);\n  return [on, toggle];\n};\n\nAs I already alluded to, another disadvantage of the container pattern is that\noften the top-level component ends up being the container that fetches a slice\nof state from the store and passes it down to its children as props.\n\nTake as an example a BookList container component that simply iterate over an\narray of books from the store and renders a BookItem in a list:\n\nimport React from \"react\";\nimport {connect} from \"react-redux\";\n\nconst BookItem = ({title, author}) => {\n  return (\n    <div>\n      <h1>{title}</h1>\n      <h2>{`by ${author}`}</h2>\n    </div>\n  );\n};\n\nconst BookList = ({books}) => {\n  return (\n    <ul>\n      {books.map(({book}) => {\n        return (\n          <li key={book.id}>\n            <BookItem {...book} />\n          <li>\n        );\n      })}\n    </ul>\n  )\n};\n\nconst mapStateToProps = state => ({\n  books: state.books.index\n});\n\nexport default connect(mapStateToProps)(BookList);\n\nA problem we might run into is that, if one book in the list is updated the\nentire list re-render which can quickly turn into an annoying performance issue.\nThat is why it's a good practice to provide data as close to where it is needed\nas possible. \n\nInstead of having to go in and add a BookItem container, we can just create a\ncustom hook.\n\nFirst BookList only receives an array of book ids, which presumably change less\nfrequently than an any particular book:\n\nimport React from \"react\";\nimport {connect} from \"react-redux\";\n\nconst BookList = ({bookIds}) => {\n  return (\n    <ul>\n      {bookIds.map(({bookId}) => {\n        return (\n          <li key={bookId}>\n            <BookItem id={bookId} />\n          <li>\n        )\n      })}\n    </ul>\n  );\n};\n\nconst mapStateToProps = state => ({\n  bookIds: state.books.ids\n});\n\nexport default connect(mapStateToProps)(BookList);\n\nThe BookItem then uses the book id to fetch its data from the store:\n\nimport React from \"react\";\nimport {useSelector} from \"react-redux\";\n\nconst BookItem = ({id}) => {\n  // we would normally pass a selector function here\n  const book = useSelector(state = state.booksById[id]);\n  return (\n    <div>\n      <h1>{book.title}</h1>\n      <h2>{`by ${book.author}`}</h2>\n    </div>\n  );\n};\n\n\nWe can neatly bundle that and even add the action creator for updating a book in\na custom useBook hook:\n\n// src/store/hooks.js\n\nconst useBook = (id) => {\n  const book = useSelector(getBook(id));\n  const dispatch = useDispatch();\n  const update = (...args) => dispatch(updateAction(id, ...args));\n  return [book, update];\n}\n\nDepending on how you structure your react redux projects you can include this\nhook as part of your redux-duck [https://github.com/erikras/ducks-modular-redux] \nor export it alongside actions and selectors inside your redux or store folder.\n\nIt is now easy to import a hook to consume data from our redux right where it is\nneeded profiting from the above mentioned performance gains.\n\nWhat is more, we effectively removed any trace of redux from our components,\ngranted we still need to wrap everything in a Provider, but the overall\nfootprint is vastly reduced. Now, wherever the tempestuous winds of the\njavascript ecosystem may carry you, you have a clean way of interacting with any\nstate management solution you choose in the future given it exposes hooks that\nyou can compose.\n\nIdeally hooks allow all our components to be dumb.","html":"<p>Received wisdom in the react community holds that you should subdivide your components into 'smart' containers and 'dumb', presentational components.</p><p>The rationale is to separate concerns. Logic and behavior such as data fetching, any interaction with the outside world, dispatching actions and other side effects go into our smart container and what our UI should look like as a function of the resulting data into our dumb component.</p><p>This idea leads to a pervasive pattern of creating container components solely for the purpose of connecting a part of the component tree to the redux store. So we end up with two components; one in a <code>containers</code> folder fetching data from the store and passing down actions and the actual component in the <code>components</code> folder. </p><p>To me, this quickly felt cumbersome and rigid, if I simply wanted a component to have access to a slice of the store, I found myself having to create an intermediary container and changing a number of imports in other files that use the component.</p><p>I also stopped putting every bit of state into the redux store and instead took advantage of react's new and improved context api to <a href=\"https://kentcdodds.com/blog/colocation\">co-locate state</a> that is confined to a specific, well-delineated part of the component tree. This raised questions such as whether consuming context should also only happen inside containers. </p><p>Besides, what are we really achieving by this kind of separation? Concerns about data access still has us change a number of files in the component tree and the hierarchy of our UI seems to dictate which components should be containers (by default the top level one).</p><p>While well-intentioned, the benefit of decoupling UI from state and behavior does not seem to warrant the overhead and complexity introduced by organizing files this way.</p><p>Luckily, we have a perfect tool to decouple data and behavior from our presentational components...</p><p>Hooks!</p><p>And wouldn't you know react-redux lets us consume its API only using hooks.</p><p>Let's look at a small (and admittedly contrived) example. Say, we want to implement a toggle button and keep the toggle state in the redux store, maybe it needs to be available globally, toggling an app wide setting.</p><p>This is what such a component could look like using redux classico:</p><pre><code class=\"language-javascript\">import React from \"react\";\nimport {connect} from \"react-redux\";\nimport {toggleAction} from \"./store/toggleActions\";\n\nconst Toggle = ({on, toggle}) =&gt; {\n  return (\n    &lt;button onClick={toggle}&gt;{on ? 'on' : 'off'}&lt;/button&gt;\n  );\n};\n\nconst mapStateToProps = state =&gt; ({\n  on: state.toggle.on\n});\n\nconst mapDispatchToProps = {toggle: toggleAction};\n\nexport default connect(mapStateToProps, mapDispatchToProps)(Toggle);\n</code></pre><p>Yes, we probably want this to be a container components wrapping a presentational component (e.g. a button) simply passing <code>on</code> and <code>toggle</code> down via props, but for the sake of simplicity we're keeping everything in one component.</p><p>Now let's refactor this to use the new redux hooks api:</p><pre><code class=\"language-javascript\">import React from \"react\";\nimport {useDispatch, useSelector} from \"react-redux\";\nimport {toggleAction} from \"./store/toggleActions\";\n\nconst Toggle = () =&gt; {\n  const on = useSelector(state =&gt; state.toggle.on);\n  const dispatch = useDispatch();\n  return (\n    &lt;button onClick={() =&gt; dispatch(toggleAction())}&gt;{on ? 'on' : 'off'}&lt;/button&gt;\n  );\n}\n</code></pre><p>Not much of an improvement, we reduced some boilerplate, but there is still a lot of redux code sitting in our component. </p><p>The beauty of hooks is how composable they are, we can just create a custom <code>useToggle</code> hook:</p><pre><code class=\"language-javascript\">import React from \"react\";\nimport {useDispatch, useSelector} from \"react-redux\";\nimport {toggleAction} from \"./store/toggleActions\";\n\nconst useToggle = () =&gt; {\n  const on = useSelector(state =&gt; state.toggle.on);\n  const dispatch = useDispatch();\n  const toggle = () =&gt;  dispatch(toggleAction());\n  return [on, toggle];\n};\n\nconst Toggle = () =&gt; {\n  const [on, toggle] = useToggle();\n  return (\n    &lt;button onClick={toggle()}&gt;{on ? 'on' : 'off'}&lt;/button&gt;\n  );\n};</code></pre><p>Now our component knows nothing about redux, we did not need to create a <code>Toggle</code> container or some abstract HOC wrapping our button, we simply use a hook to encapsulates the data layer.</p><p>This way our components are also closed to modification, should we decide to employ a different state management solution. Moving redux state into react context simply involves rewriting the hook (at least for consumers of the context):</p><pre><code class=\"language-javascript\">import ToggleContext from './ToggleContext';\nconst useToggle = () =&gt; {\n  const {on, toggle} = useContext(ToggleContext);\n  return [on, toggle];\n};</code></pre><p>As I already alluded to, another disadvantage of the container pattern is that often the top-level component ends up being the container that fetches a slice of state from the store and passes it down to its children as props.</p><p>Take as an example a <code>BookList</code> container component that simply iterate over an array of books from the store and renders a <code>BookItem</code> in a list:</p><pre><code class=\"language-javascript\">import React from \"react\";\nimport {connect} from \"react-redux\";\n\nconst BookItem = ({title, author}) =&gt; {\n  return (\n    &lt;div&gt;\n      &lt;h1&gt;{title}&lt;/h1&gt;\n      &lt;h2&gt;{`by ${author}`}&lt;/h2&gt;\n    &lt;/div&gt;\n  );\n};\n\nconst BookList = ({books}) =&gt; {\n  return (\n    &lt;ul&gt;\n      {books.map(({book}) =&gt; {\n        return (\n          &lt;li key={book.id}&gt;\n            &lt;BookItem {...book} /&gt;\n          &lt;li&gt;\n        );\n      })}\n    &lt;/ul&gt;\n  )\n};\n\nconst mapStateToProps = state =&gt; ({\n  books: state.books.index\n});\n\nexport default connect(mapStateToProps)(BookList);</code></pre><p>A problem we might run into is that, if one book in the list is updated the entire list re-render which can quickly turn into an annoying performance issue. That is why it's a good practice to provide data as close to where it is needed as possible. </p><p>Instead of having to go in and add a <code>BookItem</code> container, we can just create a custom hook.</p><p>First <code>BookList</code> only receives an array of book ids, which presumably change less frequently than an any particular book:</p><pre><code class=\"language-javascript\">import React from \"react\";\nimport {connect} from \"react-redux\";\n\nconst BookList = ({bookIds}) =&gt; {\n  return (\n    &lt;ul&gt;\n      {bookIds.map(({bookId}) =&gt; {\n        return (\n          &lt;li key={bookId}&gt;\n            &lt;BookItem id={bookId} /&gt;\n          &lt;li&gt;\n        )\n      })}\n    &lt;/ul&gt;\n  );\n};\n\nconst mapStateToProps = state =&gt; ({\n  bookIds: state.books.ids\n});\n\nexport default connect(mapStateToProps)(BookList);</code></pre><p>The <code>BookItem</code> then uses the book id to fetch its data from the store:</p><pre><code class=\"language-javascript\">import React from \"react\";\nimport {useSelector} from \"react-redux\";\n\nconst BookItem = ({id}) =&gt; {\n  // we would normally pass a selector function here\n  const book = useSelector(state = state.booksById[id]);\n  return (\n    &lt;div&gt;\n      &lt;h1&gt;{book.title}&lt;/h1&gt;\n      &lt;h2&gt;{`by ${book.author}`}&lt;/h2&gt;\n    &lt;/div&gt;\n  );\n};\n</code></pre><p>We can neatly bundle that and even add the action creator for updating a book in a custom <code>useBook</code> hook:</p><pre><code class=\"language-javascript\">// src/store/hooks.js\n\nconst useBook = (id) =&gt; {\n  const book = useSelector(getBook(id));\n  const dispatch = useDispatch();\n  const update = (...args) =&gt; dispatch(updateAction(id, ...args));\n  return [book, update];\n}</code></pre><p>Depending on how you structure your react redux projects you can include this hook as part of your <a href=\"https://github.com/erikras/ducks-modular-redux\">redux-duck</a> or export it alongside actions and selectors inside your <code>redux</code> or <code>store</code> folder.</p><p>It is now easy to import a hook to consume data from our redux right where it is needed profiting from the above mentioned performance gains.</p><p>What is more, we effectively removed any trace of redux from our components, granted we still need to wrap everything in a <code>Provider</code>, but the overall footprint is vastly reduced. Now, wherever the tempestuous winds of the javascript ecosystem may carry you, you have a clean way of interacting with any state management solution you choose in the future given it exposes hooks that you can compose.</p><p>Ideally hooks allow all our components to be dumb.</p>","url":"http://localhost:2368/decouple-from-redux-using-hooks/","canonical_url":null,"uuid":"b6b74a4c-0336-435f-af43-f5b1fd829ae5","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5e858c4e0a554e19673f4bf4","reading_time":5}},{"node":{"id":"Ghost__Post__5e73dfb21baf0e7fa30dd914","title":"'On Writing Software Well' II","slug":"on-writing-software-well-part-ii-callback","featured":true,"feature_image":"https://images.unsplash.com/photo-1556761175-b413da4baf72?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ","excerpt":"Callbacks vs. Listeners\nWe walk through how DHH employs callbacks in Basecamp to send mentions and I offer alternative approach moving code into the controller and using listeners for higher decoupling.","custom_excerpt":"Callbacks vs. Listeners\nWe walk through how DHH employs callbacks in Basecamp to send mentions and I offer alternative approach moving code into the controller and using listeners for higher decoupling.","visibility":"public","created_at_pretty":"19 March, 2020","published_at_pretty":"19 March, 2020","updated_at_pretty":"22 March, 2020","created_at":"2020-03-19T21:10:10.000+00:00","published_at":"2020-03-19T21:24:28.000+00:00","updated_at":"2020-03-22T12:18:34.000+00:00","meta_title":null,"meta_description":null,"og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Jan Bussieck","slug":"jan","bio":null,"profile_image":"//www.gravatar.com/avatar/e056f0b055ea37bd94fdc1664fca6e3d?s=250&d=mm&r=x","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Jan Bussieck","slug":"jan","bio":null,"profile_image":"//www.gravatar.com/avatar/e056f0b055ea37bd94fdc1664fca6e3d?s=250&d=mm&r=x","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Ruby on Rails","slug":"ruby-on-rails","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Ruby on Rails","slug":"ruby-on-rails","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Software Design","slug":"software-design","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Tech","slug":"tech","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Callbacks vs. Listeners\nDHH remarks that he is a big fan of callbacks since they allow you to move a lot\nof incidental complexity off to the side while the rest of the code can pretend\nto be on a simple, default path shielding the programmer from a lot of the\ncognitive load that lives in callbacks instead.\n\nTo see what that means in practice, we are going to trace the mentions feature\nin Basecamp all the way down and pay attention to how callbacks are used to that\nend.\n\nThe entry point is the create action of the messages controller, which simply\nrecords a new message on a bucket (a bucket is an abstraction used to group\ncertain entities, which will be explained in future episodes). The new_message \nmethod in turn simply instantiates a message, note that logic pertaining to the\ncreation of mentions or actual recordings is missing from the controller.\n\nclass MessagesController < ApplicationController\n...\n  def create\n    @recording = @bucket.record new_message,\n      parent: @parent_recording,\n      status: status_param,\n      subscribers: find_subscribers,\n      category: find_category\n\n    ...\n  end\n  ...\n  def new_message\n    Message.new params.require(:message).permit(:subject, :content)\n  end\n...\nend\n\n\nA mention is a model joining a mentioner and mentionee to a specific recording:\n\nclass Mention < ActiveRecord::Base\n  ...\n  belongs_to: :recording\n\n  belongs_to: mentionee, class_name: 'Person', inverse_of: :mentions\n  belongs_to: mentioner, class_name: 'Person'\n  ...\n  after_commit :deliver, unless: -> { mentioner == mentionee }, on: [:create, :update]\nend\n\n\nMentions are a simple concern which orchestrates when mentions are to be\nscheduled.\n\nmodule Recording::Mentions\n  extend ActiveSupport::Concern\n\n  included do\n    has_many :mentions\n    after_save :remember_to_eavesdrop\n    after_commit :eavesdrop_for_mentions, on: %i[ create update ], if: :eavesdropping?\n  end\n  ...\n  private\n  \n  def remember_to_eavesdrop\n    @eavesdropping = active_or_archived_recordable_changed? || draft_became_active?\n  end\n\n  def eavesdropping?\n    @eavesdropping && !Mention::Eavesdropper.suppressed? && has_mentions? \n  end\n\n  def eavesdrop_for_mentions\n    Mention::EavesdroppingJob.perform_later self, mentioner: Current.person\n  end\nend\n\n\nDHH points out a trick to track dirty attributes, circumventing a problem that\nmany Rails developers have also run into; when you run an after_commit callback\nyou can no longer access to which attributes changed invoking neither \nchanged_attributes nor the _changed? methods, since they only persist within a\ndatabase transaction.\n\nWe simply check before the transaction is committed in an after_save callback\nwhich attributes changed, make a note of it in an instance variable so that we\ncan access the information later (e.g. in the after_commit callback).\n\nHere, remember_to_eavesdrop records whether the content of the recordable record\nactually changed or whether a recordable which might contain mentions became\nactive before we scan for mentions.\n\nThe eavesdropping? query method simply checks whether the instance variable is\nset, that mentions exists and that the eavesdropping callback has not been\ndisabled via suppress. To the last point, DDH explains that while callbacks are\nsupposed to contain code that should run by default, it might sometimes be\nnecessary to disable them.\n\nFinally, after checking whether we should perform any work and scan for\nmentions, the actual work is delegated to a job via eavesdrop_for_mentions, the\njob simply instantiates an instance of Mention::Eavesdropper which creates the\nactual mentions. Also, note how the method Current, a class that allows global,\nper-request storage of attributes, is used to pass the current user as mentioner\nto the job.\n\nclass Mention::EavesdroppingJob < ApplicationJob\n  queue_as :background\n\n  def perform(recording, mentioner)\n    Current.set(account: recording.account) do\n      Mention::EavesDropper.new(recording, mentioner).create_mentions\n    end\n  end\nend\n\n\nThe EavesDropper in turn invokes a scanner that finds mentionees and creates\nmentions.\n\nclass Mention::Eavesdropper\n  extend Suppressible\n  ...\n  def create_mentions\n    recording.with_lock do\n      mentionees.each do |mentionee, callsign|\n        create_mention mentionee, callsign\n      end\n    end\n  end\nend\n\n\nThat is it, we moved the ancillary concern of creating mentions off to the side,\nby handling it in callbacks as response to certain life cycle events of our\nmodel as opposed to the 'main path' of our code inside the controller action. A\ndeveloper interested in the main path i.e. creating messages is not confronted\nwith the complexity of creating mentions right away. While it is true that this\nreduces some cognitive load in that specific case, it comes at non-negligible\ncost.\nNote how we had to trace the feature of creating mentions in response to a\nchange to a recordable record all the way from the controller, through the\nmodel's life cycle methods to a job and finally a service creating the mentions.\nAlong the way we are given hints that this level of coupling is fraught with\nsome amount amount of complication.\n\nTracking dirty attributes\nFirst off, we need intricate knowledge about Rails life cycle methods in order\nto be able to track changes to a recording and know whether we should even check\nfor mentions. I need to be cognizant of database transaction and how they relate\nto callbacks to even become aware of how to track model changes in after_commit.\nTalk about incidental complexity.\n\nChecking for suppression in callbacks\nSecondly, apparently, there are use cases where the client (whoever is\ninitiating those model updates) might not want to listen for mentions, maybe I\nam seeding data or going through an admin API that I don't want to trigger\nsending emails. Quite plausible. In those cases, I need to check whether\ncreating mention eavesdroppers has explicitly been suppressed. The problems\nintroduced by this sort of coupling have been addressed in this post. But it\nagain strikes me as very counterintuitive and error-prone to reach into a\ncompletely different class, whose internal state has been modified elsewhere in\norder to decide whether to run a callback or not.\n\nUsing Current to store request-wide state\nFinally, a problem that results from handling these types of interactions deep\ndown in active record models is that I still need information from the\ncontroller. In this case, a global object is used to register that information\nmaking it globally accessible in the entire application. That should be the\nclearest indication that I might be performing work in a class that has to know\ntoo much in order to perform it and hence might be the wrong place to do it.\n\nThe controller as mediator\nThat's enough for criticisms. I think the highlighted problems all indicate that\nwe shouldn't know what the we are trying to know inside the callback, because we\nare too far removed from where those decisions occur; the controller.\n\nI have always thought of the controller, more specifically a controller action,\nas a mediator [https://en.wikipedia.org/wiki/Mediator_pattern] encapsulating\nknowledge about a particular use case and deciding which models need to talk to\nwhich and what they need to know to accomplish their particular tasks. The\ncontroller orchestrates, passes on information and creates side effects, much in\nthe vein of Gary Bernhardt's functional core / imperative shell\n[https://www.destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell]\n.\n\nAt speqtor.com [http://speqtor.com], we have a similar feature to Basecamp's\nmentions where certain updates to models create notifications for different\nusers subscribed to that model.\n\nA typical controller action looks like this:\n\ndef update\n  load_criterion\n  build_criterion\n  authorize_criterion\n\n  subscribe_listeners(@criterion)\n\n  save_criterion\n\n  decorate_criterion\n  render_criterion\nend\n\n\nWe like sticking to the same structure in every controller which makes them easy\nto understand and to spot where interesting things are happening (See the\nexcellent Growing Rails Applications in Practice\n[https://leanpub.com/growing-rails]). Here, we are updating a criterion that\nindicates how complex a project is going to be. In this specific use case, a\nuser directly interacts with our web app, as opposed to an importer job or the\nrails console. In this context we want a number of side effects to happen as a\nresult of certain model events. This is achieved by registering event listeners,\nwhich in turn decide what is supposed to happen as a result of those changes.\n\nIn our example, we want to listen to successful updates in order to notify other\nusers.\n\nThis happens inside the SubscribesListeners concern:\n\ndef subscribe_notification_listener(options = {})\n  with_load_error_guard do\n    listener_class = options[:notification_listener_class] || infer_listener\n    listener = listener_class.new\n\n    listener.current_user = current_user\n    listener.changes = subscription_target.changes.transform_values do |val|\n      val.map(&:to_s)\n    end\n\n    subscription_target.subscribe listener, async: true\n  end\nend\n\n\nHere, we are instantiating the listener class, pass in the information it needs,\ni.e. model changes and the current user and subscribe it to the target model (in\nthis case the criterion). Often we add other information available in the\ncontroller, such as the scope of the current project or user permissions. The\nlistener, in turn, simply creates the notification.\n\nSimple enough.\n\nHow are the above problems solved here?\n\nRegarding dirty attribute tracking; since we haven't persisted the model yet, we\ncan still access model changes though the attributes api, when the model is\nsaved and the database transaction completes, the listener is merely notified of\nits success or failure.\n\nAs we are still inside the controller context we can also pass any information\nsuch as the current user to the listener without having to awkwardly store it in\na global Current.\n\nLastly, the listener is maximally decoupled, we have to explicitly opt into\ncreating notifications depending on the current use case, as opposed to\nanticipating every use case by checking related models for suppression.\n\nAn additional benefit is that, we can now easily background the listener without\nhaving to worry  about implicit state in the form of model suppression or \nCurrent registries.\n\nSo what should callbacks be used for?\n\nI am not a big fan of hard and fast rules in software design, but sometimes it's\nprudent to have certain guidelines to stick to unless there is a very good\nreason for violating them.\n\nOne of them is that callbacks should only deal with immediate model concerns,\nwhich are in declining order of popularity:\n\n 1. Maintaining data integrity and mutating the model into a valid state,\n    examples are normalizing or splitting attributes.\n 2. Mutate a closely associated model, for instance counter caches in a\n    one-to-many association.\n 3. Small side effects for related or derived data such as busting caches.","html":"<h2 id=\"callbacks-vs-listeners\">Callbacks vs. Listeners</h2><p>DHH remarks that he is a big fan of callbacks since they allow you to move a lot of incidental complexity off to the side while the rest of the code can pretend to be on a simple, default path shielding the programmer from a lot of the cognitive load that lives in callbacks instead.</p><p>To see what that means in practice, we are going to trace the mentions feature in Basecamp all the way down and pay attention to how callbacks are used to that end.</p><p>The entry point is the create action of the messages controller, which simply records a new message on a bucket (a bucket is an abstraction used to group certain entities, which will be explained in future episodes). The <code>new_message</code> method in turn simply instantiates a message, note that logic pertaining to the creation of mentions or actual recordings is missing from the controller.</p><pre><code class=\"language-ruby\">class MessagesController &lt; ApplicationController\n...\n  def create\n    @recording = @bucket.record new_message,\n      parent: @parent_recording,\n      status: status_param,\n      subscribers: find_subscribers,\n      category: find_category\n\n    ...\n  end\n  ...\n  def new_message\n    Message.new params.require(:message).permit(:subject, :content)\n  end\n...\nend\n</code></pre><p>A mention is a model joining a mentioner and mentionee to a specific recording:</p><pre><code class=\"language-ruby\">class Mention &lt; ActiveRecord::Base\n  ...\n  belongs_to: :recording\n\n  belongs_to: mentionee, class_name: 'Person', inverse_of: :mentions\n  belongs_to: mentioner, class_name: 'Person'\n  ...\n  after_commit :deliver, unless: -&gt; { mentioner == mentionee }, on: [:create, :update]\nend\n</code></pre><p>Mentions are a simple concern which orchestrates when mentions are to be scheduled.</p><pre><code class=\"language-ruby\">module Recording::Mentions\n  extend ActiveSupport::Concern\n\n  included do\n    has_many :mentions\n    after_save :remember_to_eavesdrop\n    after_commit :eavesdrop_for_mentions, on: %i[ create update ], if: :eavesdropping?\n  end\n  ...\n  private\n  \n  def remember_to_eavesdrop\n    @eavesdropping = active_or_archived_recordable_changed? || draft_became_active?\n  end\n\n  def eavesdropping?\n    @eavesdropping &amp;&amp; !Mention::Eavesdropper.suppressed? &amp;&amp; has_mentions? \n  end\n\n  def eavesdrop_for_mentions\n    Mention::EavesdroppingJob.perform_later self, mentioner: Current.person\n  end\nend\n</code></pre><p>DHH points out a trick to track dirty attributes, circumventing a problem that many Rails developers have also run into; when you run an <code>after_commit</code> callback you can no longer access to which attributes changed invoking neither <code>changed_attributes</code> nor the <code>_changed?</code> methods, since they only persist within a database transaction.</p><p>We simply check before the transaction is committed in an <code>after_save</code> callback which attributes changed, make a note of it in an instance variable so that we can access the information later (e.g. in the <code>after_commit</code> callback).</p><p>Here, <code>remember_to_eavesdrop</code> records whether the content of the recordable record actually changed or whether a recordable which might contain mentions became active before we scan for mentions.</p><p>The <code>eavesdropping?</code> query method simply checks whether the instance variable is set, that mentions exists and that the eavesdropping callback has not been disabled via <code>suppress</code>. To the last point, DDH explains that while callbacks are supposed to contain code that should run by default, it might sometimes be necessary to disable them.</p><p>Finally, after checking whether we should perform any work and scan for mentions, the actual work is delegated to a job via <code>eavesdrop_for_mentions</code>, the job simply instantiates an instance of <code>Mention::Eavesdropper</code> which creates the actual mentions. Also, note how the method <code>Current,</code> a class that allows global, per-request storage of attributes, is used to pass the current user as mentioner to the job.</p><pre><code class=\"language-ruby\">class Mention::EavesdroppingJob &lt; ApplicationJob\n  queue_as :background\n\n  def perform(recording, mentioner)\n    Current.set(account: recording.account) do\n      Mention::EavesDropper.new(recording, mentioner).create_mentions\n    end\n  end\nend\n</code></pre><p>The <code>EavesDropper</code> in turn invokes a scanner that finds mentionees and creates mentions.</p><pre><code class=\"language-ruby\">class Mention::Eavesdropper\n  extend Suppressible\n  ...\n  def create_mentions\n    recording.with_lock do\n      mentionees.each do |mentionee, callsign|\n        create_mention mentionee, callsign\n      end\n    end\n  end\nend\n</code></pre><p>That is it, we moved the ancillary concern of creating mentions off to the side, by handling it in callbacks as response to certain life cycle events of our model as opposed to the 'main path' of our code inside the controller action. A developer interested in the main path i.e. creating messages is not confronted with the complexity of creating mentions right away. While it is true that this reduces some cognitive load in that specific case, it comes at non-negligible cost.<br>Note how we had to trace the feature of creating mentions in response to a change to a recordable record all the way from the controller, through the model's life cycle methods to a job and finally a service creating the mentions. Along the way we are given hints that this level of coupling is fraught with some amount amount of complication.</p><h3 id=\"tracking-dirty-attributes\">Tracking dirty attributes</h3><p>First off, we need intricate knowledge about Rails life cycle methods in order to be able to track changes to a recording and know whether we should even check for mentions. I need to be cognizant of database transaction and how they relate to callbacks to even become aware of how to track model changes in <code>after_commit</code>. Talk about incidental complexity.</p><h3 id=\"checking-for-suppression-in-callbacks\">Checking for suppression in callbacks</h3><p>Secondly, apparently, there are use cases where the client (whoever is initiating those model updates) might not want to listen for mentions, maybe I am seeding data or going through an admin API that I don't want to trigger sending emails. Quite plausible. In those cases, I need to check whether creating mention eavesdroppers has explicitly been suppressed. The problems introduced by this sort of coupling have been addressed in this post. But it again strikes me as very counterintuitive and error-prone to reach into a completely different class, whose internal state has been modified elsewhere in order to decide whether to run a callback or not.</p><h3 id=\"using-current-to-store-request-wide-state\">Using <code>Current</code> to store request-wide state</h3><p>Finally, a problem that results from handling these types of interactions deep down in active record models is that I still need information from the controller. In this case, a global object is used to register that information making it globally accessible in the entire application. That should be the clearest indication that I might be performing work in a class that has to know too much in order to perform it and hence might be the wrong place to do it.</p><h3 id=\"the-controller-as-mediator\">The controller as mediator</h3><p>That's enough for criticisms. I think the highlighted problems all indicate that we shouldn't know what the we are trying to know inside the callback, because we are too far removed from where those decisions occur; the controller.</p><p>I have always thought of the controller, more specifically a controller action, as a <a href=\"https://en.wikipedia.org/wiki/Mediator_pattern\">mediator</a> encapsulating knowledge about a particular use case and deciding which models need to talk to which and what they need to know to accomplish their particular tasks. The controller orchestrates, passes on information and creates side effects, much in the vein of Gary Bernhardt's <a href=\"https://www.destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell\">functional core / imperative shell</a>.</p><p>At <a href=\"http://speqtor.com\">speqtor.com</a>, we have a similar feature to Basecamp's mentions where certain updates to models create notifications for different users subscribed to that model.</p><p>A typical controller action looks like this:</p><pre><code class=\"language-ruby\">def update\n  load_criterion\n  build_criterion\n  authorize_criterion\n\n  subscribe_listeners(@criterion)\n\n  save_criterion\n\n  decorate_criterion\n  render_criterion\nend\n</code></pre><p>We like sticking to the same structure in every controller which makes them easy to understand and to spot where interesting things are happening (See the excellent <a href=\"https://leanpub.com/growing-rails\">Growing Rails Applications in Practice</a>). Here, we are updating a criterion that indicates how complex a project is going to be. In this specific use case, a user directly interacts with our web app, as opposed to an importer job or the rails console. In this context we want a number of side effects to happen as a result of certain model events. This is achieved by registering event listeners, which in turn decide what is supposed to happen as a result of those changes.</p><p>In our example, we want to listen to successful updates in order to notify other users.</p><p>This happens inside the <code>SubscribesListeners</code> concern:</p><pre><code class=\"language-ruby\">def subscribe_notification_listener(options = {})\n  with_load_error_guard do\n    listener_class = options[:notification_listener_class] || infer_listener\n    listener = listener_class.new\n\n    listener.current_user = current_user\n    listener.changes = subscription_target.changes.transform_values do |val|\n      val.map(&amp;:to_s)\n    end\n\n    subscription_target.subscribe listener, async: true\n  end\nend\n</code></pre><p>Here, we are instantiating the listener class, pass in the information it needs, i.e. model changes and the current user and subscribe it to the target model (in this case the criterion). Often we add other information available in the controller, such as the scope of the current project or user permissions. The listener, in turn, simply creates the notification.</p><p>Simple enough.</p><p>How are the above problems solved here?</p><p>Regarding dirty attribute tracking; since we haven't persisted the model yet, we can still access model changes though the attributes api, when the model is saved and the database transaction completes, the listener is merely notified of its success or failure.</p><p>As we are still inside the controller context we can also pass any information such as the current user to the listener without having to awkwardly store it in a global <code>Current</code>.</p><p>Lastly, the listener is maximally decoupled, we have to explicitly opt into creating notifications depending on the current use case, as opposed to anticipating every use case by checking related models for suppression.</p><p>An additional benefit is that, we can now easily background the listener without having to worry  about implicit state in the form of model suppression or <code>Current</code> registries.</p><p>So what should callbacks be used for?</p><p>I am not a big fan of hard and fast rules in software design, but sometimes it's prudent to have certain guidelines to stick to unless there is a very good reason for violating them.</p><p>One of them is that callbacks should only deal with immediate model concerns, which are in declining order of popularity:</p><ol><li>Maintaining data integrity and mutating the model into a valid state, examples are normalizing or splitting attributes.</li><li>Mutate a closely associated model, for instance counter caches in a one-to-many association.</li><li>Small side effects for related or derived data such as busting caches.</li></ol>","url":"http://localhost:2368/on-writing-software-well-part-ii-callback/","canonical_url":null,"uuid":"77cf93ca-42f0-44a2-b986-3cb07cf9f3a5","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5e73dfb21baf0e7fa30dd914","reading_time":6}},{"node":{"id":"Ghost__Post__5e7383d91baf0e7fa30dd890","title":"'On Writing Software Well' I","slug":"on-writing-software-well-part-1","featured":false,"feature_image":"https://images.unsplash.com/photo-1556742044-3c52d6e88c62?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ","excerpt":"Comments and Extracting Rails Features\n\nWe're looking at DHH's series to talk about software design using real world software with alls its trade-offs, necessary messiness and complexity so neatly omitted in your standard textbook toy examples.","custom_excerpt":"Comments and Extracting Rails Features\n\nWe're looking at DHH's series to talk about software design using real world software with alls its trade-offs, necessary messiness and complexity so neatly omitted in your standard textbook toy examples.","visibility":"public","created_at_pretty":"19 March, 2020","published_at_pretty":"19 March, 2020","updated_at_pretty":"20 March, 2020","created_at":"2020-03-19T14:38:17.000+00:00","published_at":"2020-03-19T15:57:00.000+00:00","updated_at":"2020-03-20T14:58:59.000+00:00","meta_title":"Ruby on Rails: Writing Software Well Part 1","meta_description":"Part 1 deals with expressive constants and code colocation and the dos and donts of using exception as control flow.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Jan Bussieck","slug":"jan","bio":null,"profile_image":"//www.gravatar.com/avatar/e056f0b055ea37bd94fdc1664fca6e3d?s=250&d=mm&r=x","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Jan Bussieck","slug":"jan","bio":null,"profile_image":"//www.gravatar.com/avatar/e056f0b055ea37bd94fdc1664fca6e3d?s=250&d=mm&r=x","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Ruby on Rails","slug":"ruby-on-rails","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Ruby on Rails","slug":"ruby-on-rails","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Software Design","slug":"software-design","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Tech","slug":"tech","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Comments and Extracting Rails Features \nDHH has drawn back the curtain on how Basecamp writes software in a video\nseries, tentatively titled 'On Writing Software (well?)', I find it highly\ninstructive and valuable to talk about software design using real world software\nwith alls its trade-offs, necessary messiness and complexity so neatly omitted\nin your standard textbook toy examples.\n\nWhile I do lay out the contents of each episode, this is not a series plain\ntranscript, but rather a way for me to engage with the challenges raised in DHHs\nexamples, add my own thoughts and, at times, contrast his approach with the one\nwe took for speqtor.com [http://speqtor.com] sharing examples from our code\nbase.\n\nEpisode 1\nWhile Code comments are sometimes necessary to explain certain decisions or\ntrade-offs that aren't obvious from the code, more often than not comments are a\nkind of code smell. \n\nYou should ask yourself why am I writing this comment? How could the code itself\nbe clearer and not need this comment?\n\nEvery developer is familiar with arcane, outdated comments in the midst of\nseemingly unrelated code, because the related code had been deleted. Another\nadvantage of self-explanatory code apart from just being clearer (by definition)\nis that it preempts the problem of code and its explanation getting out of sync.\n\ndef remove_inaccessible_records\n  # 30s of forgiveness in case of accidental removal\n  unless person.destroyed? || bucket.destroyed\n    Person::RemoveInaccessibleRecordJob.set(wait: 30.seconds).perform_later(person, bucket)\n  end\nend\n\nThe Basecamp codebase includes a method to remove all inaccessible records after\na user has been deleting, because restoring a user's objects in the bucket is\ncumbersome a 30 second grace period was added in case a user is accidentally\nremoved.\n\nA comment explains not the control flow, but the configuration of the job.\n\nWe could simply add an explanatory variable elucidating the magic value of 30\nseconds and hinting at its purpose.\n\ndef remove_inaccessible_records\n  grace_period_removing_inaccessible_records = 30.seconds\n\n  unless person.destroyed? || bucket.destroyed?\n    Person::RemoveInaccessibleRecordJob.set(wait: 30.seconds).perform_later(person, bucket)\n  end\nend\n\nHowever, the value does not vary, so why store it in a variable, it should be a\nconstant. But instead of defining it at the top of the file, as we idiomatically\nwould for public constants in ruby, we should prefer colocating related code and\nmaking the constant private.\n\nprivate\nGRACE_PERIOD_REMOVING_INACCESSIBLE_RECORDS = 30.seconds\n\ndef remove_inaccessible_records\n  unless person.destroyed? || bucket.destroyed?\n  Person::RemoveInaccessibleRecordJob.set(\n    wait: GRACE_PERIOD_REMOVING_INACCESSIBLE_RECORDS\n  ).perform_later(person, bucket)\n  end\nend\n\nI would go a step further and separate configuration from my app code,\nespecially since often you might want to have different values for different\nenvironments, for instance in testing environment you might want the job to\nexecute immediately and not wait 30 seconds.\n\nMore importantly, I have a central place to go looking for configuration options\nin my applications and they're not scattered across my source code. In Speqtor,\nfor example, we only send out a notification if no new notifications for a user\nwere scheduled within a certain cool down period, so as not to clog up their\ninbox.\n\nThe config options are defined in config/notifications.yml\n\nproduction:\n  cool_off_period_in_minutes: 20\ndevelopment:\n  cool_off_period_in_minutes: 0.2\ntest:\n  cool_off_period_in_minutes: 0\n\nand included it in application.rb  under the rails namespace config.x for\ncustom\nconfiguration.\n[https://guides.rubyonrails.org/configuring.html#custom-configuration]\n\nconfig.x.notification = config_for(:notification)\n\nBack to DHH, who show us an example of how some of his refactorings lead to new\nfeatures in Rails. In Basecamp there is a join model for granting users\nadministrative access to certain resource and a helper method grant that accepts\na person argument and creates an entry for the person in the join model, if an\nentry already exists it simply returns the person record.\n\nWhat might jump out at you about this method is that it commits the sin of using\nan exception for controlling flow. The dual offense of using framework\nexceptions in your code is that it also mixes two different levels of\nabstraction, in this case the top-level ActiveRecord API and constants from the\nbowels of ActiveRecord.\n\nmodule Account::Administered\n  extend ActiveSupport::Concern\n\n  included do\n    has_many :administratorships\n\n    def grant(person)\n\t  create! person: person\n        rescue ActiveRecord::RecordNotUnique\n        # don't worry about dupes. Treat them the same as successful creation\n        where(person: person).take\n      end\n    end\n  end\nend\n\nThe reason we are avoiding ActiveRecord's find_or_initialize_by here is that we\nmight end up with stale reads, as find_or_initialize_by first checks whether a\nrecord with the attributes exists using a where query and returns it if it does\nor else creates one with those attributes.\n\nIn applications with high load this could lead to the result returned by the \nwhere clause to being outdated, in which case the create might fail, because the\nrecord has already been created in the interim. Hence, we are first attempting\nto create the record and if that fails because it already exists we simply\nreturn it.\n\nSo what we actually want is create_of_find_by(person: person) which encapsulate\nthis behavior and simplifies this code to a mere delegation:\n\ndef grant(person)\n  create_or_find_by(person: person)\nend\n\nAnd indeed, this method has made it into Rails 6 and it's arguably what \nfind_or_create_by should have been from the beginning.\n\nJust a note on the topic of exceptions as a flow control; in this instance, I\nthink it is perfectly fine to do so (and in fact the Rails method does just that\n[https://github.com/rails/rails/blob/f675cb30ce813a99b52b139a93e048330922fd9a/activerecord/lib/active_record/relation.rb#L218]\n), because we are relying on the database's mechanism for ensuring data\nconsistency and simply pass the exception through to the caller. We could not\nhave performed this check without dealing with the database exception, since\nthis is the only interface offered to our application code.","html":"<h2 id=\"comments-and-extracting-rails-features\">Comments and Extracting Rails Features </h2><p>DHH has drawn back the curtain on how Basecamp writes software in a video series, tentatively titled 'On Writing Software (well?)', I find it highly instructive and valuable to talk about software design using real world software with alls its trade-offs, necessary messiness and complexity so neatly omitted in your standard textbook toy examples.</p><p>While I do lay out the contents of each episode, this is not a series plain transcript, but rather a way for me to engage with the challenges raised in DHHs examples, add my own thoughts and, at times, contrast his approach with the one we took for <a href=\"http://speqtor.com\">speqtor.com</a> sharing examples from our code base.</p><h2 id=\"episode-1\">Episode 1</h2><p>While Code comments are sometimes necessary to explain certain decisions or trade-offs that aren't obvious from the code, more often than not comments are a kind of code smell. </p><p>You should ask yourself <em>why</em> am I writing this comment? How could the code itself be clearer and not need this comment?</p><p>Every developer is familiar with arcane, outdated comments in the midst of seemingly unrelated code, because the related code had been deleted. Another advantage of self-explanatory code apart from just being clearer (by definition) is that it preempts the problem of code and its explanation getting out of sync.</p><pre><code class=\"language-ruby\">def remove_inaccessible_records\n  # 30s of forgiveness in case of accidental removal\n  unless person.destroyed? || bucket.destroyed\n    Person::RemoveInaccessibleRecordJob.set(wait: 30.seconds).perform_later(person, bucket)\n  end\nend</code></pre><p>The Basecamp codebase includes a method to remove all inaccessible records after a user has been deleting, because restoring a user's objects in the bucket is cumbersome a 30 second grace period was added in case a user is accidentally removed.</p><p>A comment explains not the control flow, but the configuration of the job.</p><p>We could simply add an <em>explanatory variable</em> elucidating the magic value of 30 seconds and hinting at its purpose.</p><pre><code class=\"language-ruby\">def remove_inaccessible_records\n  grace_period_removing_inaccessible_records = 30.seconds\n\n  unless person.destroyed? || bucket.destroyed?\n    Person::RemoveInaccessibleRecordJob.set(wait: 30.seconds).perform_later(person, bucket)\n  end\nend</code></pre><p>However, the value does not vary, so why store it in a variable, it should be a constant. But instead of defining it at the top of the file, as we idiomatically would for public constants in ruby, we should prefer colocating related code and making the constant private.</p><pre><code class=\"language-ruby\">private\nGRACE_PERIOD_REMOVING_INACCESSIBLE_RECORDS = 30.seconds\n\ndef remove_inaccessible_records\n  unless person.destroyed? || bucket.destroyed?\n  Person::RemoveInaccessibleRecordJob.set(\n    wait: GRACE_PERIOD_REMOVING_INACCESSIBLE_RECORDS\n  ).perform_later(person, bucket)\n  end\nend</code></pre><p>I would go a step further and separate configuration from my app code, especially since often you might want to have different values for different environments, for instance in testing environment you might want the job to execute immediately and not wait 30 seconds.</p><p>More importantly, I have a central place to go looking for configuration options in my applications and they're not scattered across my source code. In Speqtor, for example, we only send out a notification if no new notifications for a user were scheduled within a certain cool down period, so as not to clog up their inbox.</p><p>The config options are defined in <code>config/notifications.yml</code></p><pre><code class=\"language-ruby\">production:\n  cool_off_period_in_minutes: 20\ndevelopment:\n  cool_off_period_in_minutes: 0.2\ntest:\n  cool_off_period_in_minutes: 0</code></pre><p>and included it in application.rb  under the rails namespace config.x <a href=\"https://guides.rubyonrails.org/configuring.html#custom-configuration\" rel=\"noopener noreferrer\">for custom configuration.</a></p><p><code>config.x.notification = config_for(:notification)</code></p><p>Back to DHH, who show us an example of how some of his refactorings lead to new features in Rails. In Basecamp there is a join model for granting users administrative access to certain resource and a helper method <code>grant</code> that accepts a <code>person</code> argument and creates an entry for the person in the join model, if an entry already exists it simply returns the person record.</p><p>What might jump out at you about this method is that it commits the sin of using an exception for controlling flow. The dual offense of using framework exceptions in your code is that it also mixes two different levels of abstraction, in this case the top-level ActiveRecord API and constants from the bowels of ActiveRecord.</p><pre><code class=\"language-ruby\">module Account::Administered\n  extend ActiveSupport::Concern\n\n  included do\n    has_many :administratorships\n\n    def grant(person)\n\t  create! person: person\n        rescue ActiveRecord::RecordNotUnique\n        # don't worry about dupes. Treat them the same as successful creation\n        where(person: person).take\n      end\n    end\n  end\nend</code></pre><p>The reason we are avoiding ActiveRecord's <code>find_or_initialize_by</code> here is that we might end up with stale reads, as <code>find_or_initialize_by</code>  first checks whether a record with the attributes exists using a <code>where</code> query and returns it if it does or else creates one with those attributes.</p><p>In applications with high load this could lead to the result returned by the <code>where</code> clause to being outdated, in which case the create might fail, because the record has already been created in the interim. Hence, we are first attempting to create the record and if that fails because it already exists we simply return it.</p><p>So what we actually want is <code>create_of_find_by(person: person)</code> which encapsulate this behavior and simplifies this code to a mere delegation:</p><pre><code class=\"language-ruby\">def grant(person)\n  create_or_find_by(person: person)\nend</code></pre><p>And indeed, this method has made it into Rails 6 and it's arguably what <code>find_or_create_by</code> should have been from the beginning.</p><p>Just a note on the topic of exceptions as a flow control; in this instance, I think it is perfectly fine to do so (<a href=\"https://github.com/rails/rails/blob/f675cb30ce813a99b52b139a93e048330922fd9a/activerecord/lib/active_record/relation.rb#L218\">and in fact the Rails method does just that</a>), because we are relying on the database's mechanism for ensuring data consistency and simply pass the exception through to the caller. We could not have performed this check without dealing with the database exception, since this is the only interface offered to our application code.</p>","url":"http://localhost:2368/on-writing-software-well-part-1/","canonical_url":null,"uuid":"417d7f35-e02b-4545-840b-0bea7d642e0e","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5e7383d91baf0e7fa30dd890","reading_time":4}},{"node":{"id":"Ghost__Post__5e775954b1f6866d5f7a0712","title":"Deep Learning and the Innovator's Dilemma","slug":"deep-learning-and-the-innovators-dilemma","featured":false,"feature_image":"https://images.unsplash.com/photo-1503039153293-d4d2ba067754?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ","excerpt":"What enables an innovations in AI to be disruptive given the fact that incumbents, generally, have both the know-how (in fact they are often the source of the innovation) and the resources to get a head start on any entrant?","custom_excerpt":"What enables an innovations in AI to be disruptive given the fact that incumbents, generally, have both the know-how (in fact they are often the source of the innovation) and the resources to get a head start on any entrant?","visibility":"public","created_at_pretty":"22 March, 2020","published_at_pretty":"22 October, 2017","updated_at_pretty":"22 March, 2020","created_at":"2020-03-22T12:25:56.000+00:00","published_at":"2017-10-22T00:00:00.000+00:00","updated_at":"2020-03-22T12:32:57.000+00:00","meta_title":null,"meta_description":null,"og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Jan Bussieck","slug":"jan","bio":null,"profile_image":"//www.gravatar.com/avatar/e056f0b055ea37bd94fdc1664fca6e3d?s=250&d=mm&r=x","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Jan Bussieck","slug":"jan","bio":null,"profile_image":"//www.gravatar.com/avatar/e056f0b055ea37bd94fdc1664fca6e3d?s=250&d=mm&r=x","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"AI","slug":"ai","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"AI","slug":"ai","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Business","slug":"business","description":null,"feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"This article was originally published on deeplearningweekly.com\n\nMostly everyone seems to agree that AI, carried by a wave of deep learning\nbreakthroughs, will 'disrupt' industries left and right. Of course, the term\ndisruption is often somewhat carelessly and imprecisely bandied about to refer\nto technological or business model innovations that threaten industry\nincumbents. But what exactly enables an innovation to be disruptive given the\nfact that incumbents, generally, have both the know-how (in fact they are often\nthe source of the innovation) and the resources to get a head start on any\nentrant is often glossed over.\n\nBefore we turn to the case of disruption through deep learning innovations, let\nus briefly explore an answer to this question presented by Clay Christensen and\nhis seminal thesis on the Innovator's Dilemma\n[https://www.amazon.com/Innovators-Dilemma-Technologies-Management-Innovation/dp/1633691780/ref=sr_1_1?ie=UTF8&qid=1487508722&sr=8-1&keywords=innovator%27s+dilemma]\n. The central thesis is that incumbent firms operate in a certain context of\ncustomer needs, suppliers, target markets and competitors that form a value\nnetwork which sets the standard of value for any strategy or business decision\nincluding where to allocate resources and which innovations to pursue. In\npractice this means that firms will often pursue sustaining innovations, that is\ninnovations which improve and sustain the firm's position within the established\nvalue network.\n\nRead the rest of the article on deeplearningweekly.com\n[https://www.deeplearningweekly.com/blog/deep-learning-and-the-innovator-s-dilemma/]","html":"<p>This article was originally published on <a href=\"http://localhost:2368/deep-learning-and-the-innovators-dilemma/deeplearningweekly.com\">deeplearningweekly.com</a></p><p>Mostly everyone seems to agree that AI, carried by a wave of deep learning breakthroughs, will 'disrupt' industries left and right. Of course, the term disruption is often somewhat carelessly and imprecisely bandied about to refer to technological or business model innovations that threaten industry incumbents. But what exactly enables an innovation to be disruptive given the fact that incumbents, generally, have both the know-how (in fact they are often the source of the innovation) and the resources to get a head start on any entrant is often glossed over.</p><p>Before we turn to the case of disruption through deep learning innovations, let us briefly explore an answer to this question presented by Clay Christensen and his seminal thesis on the <a href=\"https://www.amazon.com/Innovators-Dilemma-Technologies-Management-Innovation/dp/1633691780/ref=sr_1_1?ie=UTF8&amp;qid=1487508722&amp;sr=8-1&amp;keywords=innovator%27s+dilemma\">Innovator's Dilemma</a>. The central thesis is that incumbent firms operate in a certain context of customer needs, suppliers, target markets and competitors that form a <strong>value network</strong> which sets the standard of value for any strategy or business decision including where to allocate resources and which innovations to pursue. In practice this means that firms will often pursue <strong>sustaining innovations</strong>, that is innovations which improve and sustain the firm's position within the established value network.</p><p>Read the rest of the article on <a href=\"https://www.deeplearningweekly.com/blog/deep-learning-and-the-innovator-s-dilemma/\">deeplearningweekly.com</a></p>","url":"http://localhost:2368/deep-learning-and-the-innovators-dilemma/","canonical_url":null,"uuid":"3216c6d9-284d-488f-a604-42771d0a7b19","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5e775954b1f6866d5f7a0712","reading_time":1}}]}},"pageContext":{"pageNumber":0,"humanPageNumber":1,"skip":0,"limit":12,"numberOfPages":1,"previousPagePath":"","nextPagePath":""}}}